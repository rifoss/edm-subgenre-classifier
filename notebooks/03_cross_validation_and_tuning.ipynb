{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4ebc8c-867c-4cba-8383-12ace1ac89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import the cross-validation tool\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d8dcc3-4f71-401a-bef9-4eeb2a915467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Load the data, keeping the features (X) and target (y) separated\n",
    "iris = load_iris(as_frame=True)\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "print(f\"Total samples: {len(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d4ecf5-b2fd-4bec-8dba-377a905f24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model instantiated.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "print(\"Logistic Regression model instantiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbb456d-9392-4f29-8a33-d9127709eff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Cross-Validation Scores (5 Folds):\n",
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-Fold Cross-Validation (CV)\n",
    "# cv=5 means 5 folds. The scoring='accuracy' tells it what metric to return.\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=logreg, # The model to use\n",
    "    X=x,              # The FULL feature set (CV handles the splitting)\n",
    "    y=y,              # The FULL target set\n",
    "    cv=5,             # Number of folds\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"Individual Cross-Validation Scores (5 Folds):\")\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16564f2b-131b-4521-9082-62110a7015d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean CV Accuracy: 0.9733\n",
      "Standard Deviation of CV Scores: 0.0249\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean (average performance)\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "\n",
    "# Calculate the standard deviation (measure of variability/robustness)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\nMean CV Accuracy: {mean_cv_score:.4f}\")\n",
    "print(f\"Standard Deviation of CV Scores: {std_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7891d79-b22b-4b22-92b6-4dae9bb08598",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean accuracy = High, therefore model is relatively accurate\n",
    "## Std Dev = Low, therefore model is precise i.e. repeatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c636d4-6933-45de-ba07-b1fd0df616c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the remaining classifiers needed for comparison\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier # Adding KNN back for full comparison\n",
    "\n",
    "# Instantiate all the models you want to test\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=200, random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('SVC', SVC(random_state=42))\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "cv_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc3affb-c560-44b5-abce-3b5bbfd9421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed CV for: Logistic Regression\n",
      "Completed CV for: KNN\n",
      "Completed CV for: Random Forest\n",
      "Completed CV for: SVC\n",
      "\n",
      "All CV runs complete.\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-Fold CV for each model\n",
    "for name, model in models:\n",
    "    # Use cross_val_score\n",
    "    cv_scores = cross_val_score(\n",
    "        estimator = model,\n",
    "        X = x,\n",
    "        y = y,\n",
    "        cv = 5,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    # Store the avg score and std.dev\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean CV Accuracy': np.mean(cv_scores),\n",
    "        'STD': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    print(f\"Completed CV for: {name}\")\n",
    "\n",
    "print(\"\\nAll CV runs complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba90b108-5af9-4ec8-b322-6d63863d2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cross-Validation Model Comparison ---\n",
      "                 Model Mean CV Accuracy     STD\n",
      "0  Logistic Regression           0.9733  0.0249\n",
      "1                  KNN           0.9667  0.0211\n",
      "2        Random Forest           0.9667  0.0211\n",
      "3                  SVC           0.9667  0.0211\n"
     ]
    }
   ],
   "source": [
    "# Create the comparison table\n",
    "cv_summary_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Format the results for better readability and sort by accuracy\n",
    "cv_summary_df['Mean CV Accuracy'] = cv_summary_df['Mean CV Accuracy'].map('{:.4f}'.format)\n",
    "cv_summary_df['STD'] = cv_summary_df['STD'].map('{:.4f}'.format)\n",
    "cv_summary_df = cv_summary_df.sort_values(by='Mean CV Accuracy', ascending=False)\n",
    "\n",
    "print(\"--- Cross-Validation Model Comparison ---\")\n",
    "print(cv_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955c04ae-4005-4c77-a005-eca33599fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tuning tool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import the model we are tuning (SVC)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96dcde9-42ad-469b-b80b-fc50cfe53c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid defined. testing 4 * 4 * 1 = 16 combinations.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid (all combinations of these values will be tested)\n",
    "param_grid = {\n",
    "    # Test C values\n",
    "    'C' : [0.1, 1, 10, 100],\n",
    "    # Test gamma values\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    # We will only use the Radial Basis Function (RBF) kernel\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "print(\"Parameter grid defined. testing 4 * 4 * 1 = 16 combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90edc438-a366-4957-8944-b211f7609427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SVC model\n",
    "svc_base = SVC(random_state=42)\n",
    "\n",
    "#Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = svc_base,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy', # Metric to optimize\n",
    "    cv = 5,              # Use 5-Fold Cross-Validation\n",
    "    verbose = 3,         # Shows progress output during the long run\n",
    "    n_jobs = -1          # Use all available CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d7687a7-4cd6-4210-997f-a5a44e4ce679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Grid Search Completed.\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(x,y)\n",
    "\n",
    "print(\"\\nGrid Search Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e1f536-bfd3-4ceb-9568-72e793480db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean CV Accuracy found: 0.9800\n",
      "Best Hyperparameters:\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Get highest score\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best Mean CV Accuracy found: {best_score:.4f}\")\n",
    "\n",
    "# Get the combination of settings with highest score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Store the final, best-tuned model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346a15b-b75b-445f-be6a-dd97cea3a7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
